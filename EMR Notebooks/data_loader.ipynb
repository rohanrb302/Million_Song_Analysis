{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>17</td><td>application_1606590675617_0018</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-21-27.ec2.internal:20888/proxy/application_1606590675617_0018/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-26-250.ec2.internal:8042/node/containerlogs/container_1606590675617_0018_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import required packages/libraries:\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "# Dependencies for Regression Algorithms:\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.regression import IsotonicRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define sql context:\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the csv file(stored in DBFS) as a Spark dataframe:\n",
    "df = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\",\"true\").load(\"s3://projectmlldsongs/processed_songs/*.csv\")\n",
    "\n",
    "# Cache the dataframe across all workers:\n",
    "#df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true"
     ]
    }
   ],
   "source": [
    "print(sc.getConf().get('spark.dynamicAllocation.enabled'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453250"
     ]
    }
   ],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Usue Regex to filter numeric entries in target column i.e. 'song_hotttnesss':\n",
    "expr = \"(^[+-]?([0-9]*[.])?[0-9]+)\"\n",
    "df = (df.filter(df.song_hotttnesss.rlike(expr)))\n",
    "df = df.filter(df.song_hotttnesss > 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Seperate and typecast features having numeric entries:\n",
    "numeric_columns=['artist_familiarity',\n",
    "                 'artist_hotttnesss',\n",
    "                 'duration',\n",
    "                 'end_of_fade_in',\n",
    "                 'energy',\n",
    "                 'mode',\n",
    "                 'key',\n",
    "                 'key_confidence',\n",
    "                 'loudness',\n",
    "                 'song_hotttnesss',\n",
    "                 'tempo',\n",
    "                 'time_signature',\n",
    "                 'time_signature_confidence',\n",
    "                 'year']\n",
    "\n",
    "for c in numeric_columns:\n",
    "    df=df.withColumn(c,df[c].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop rows with null/NA values and duplicates:\n",
    "df = df.na.drop()\n",
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select columns for the regression model:\n",
    "select_df = df.select([ 'artist_familiarity','duration','loudness','key_confidence','key','end_of_fade_in',\n",
    "                       'time_signature_confidence','tempo','mode','song_hotttnesss'])\n",
    "\n",
    "# Split dataset into train and validation sets:\n",
    "train_df,test_df_model =select_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.write.parquet(\"s3://projectmlldsongs/songs_data_split/type=train/\")\n",
    "test_df_model.write.parquet(\"s3://projectmlldsongs/songs_data_split/type=test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.parquet(\"s3://whatever/type=train/\").where(\"type = 'train'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Rows of dataframe to Dense Vectors:\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['artist_familiarity','duration','loudness','key_confidence','key','end_of_fade_in',\n",
    "               'time_signature_confidence','tempo','mode'],\n",
    "    outputCol='features')\n",
    "\n",
    "# Create linear regression object\n",
    "lr = LinearRegression(labelCol='song_hotttnesss', featuresCol='features')\n",
    "\n",
    "# Create a pipeline to sequentially perform operations on the training set:\n",
    "pipeline = Pipeline(stages=[assembler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 4-fold cross validation on the train dataset:\n",
    "#paramGrid = ParamGridBuilder()\\\n",
    "#    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "#    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "#    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "#    .build()\n",
    "\n",
    "#crossval = CrossValidator(estimator=pipeline,\n",
    "#                          estimatorParamMaps=paramGrid,\n",
    "#                          evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"song_hotttnesss\",predictionCol=\"prediction\"),\n",
    "#                          numFolds=4)\n",
    "\n",
    "#Train the model:\n",
    "lrmodel = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "predictions = lrmodel.transform(test_df_model)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"song_hotttnesss\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"song_hotttnesss\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "# Print RMSE:\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print r2 value:\n",
    "print(f\" The r2 value is {lrmodel.stages[1].summary.r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GBT regression object:\n",
    "xgb = GBTRegressor(featuresCol=\"features\",labelCol=\"song_hotttnesss\",maxIter =10)\n",
    "\n",
    "# Chain indexer and forest in a Pipeline. Use same assembler object as before:\n",
    "pipeline = Pipeline(stages=[assembler, xgb])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model_xgb = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test dataset:\n",
    "predictions_xgb = model_xgb.transform(test_df_model)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_xgb.select(\"prediction\", \"song_hotttnesss\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator_xgb = RegressionEvaluator(\n",
    "    labelCol=\"song_hotttnesss\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator_xgb.evaluate(predictions_xgb)\n",
    "\n",
    "# Print RMSE:\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Isotonic Regression object:\n",
    "isoreg = IsotonicRegression(featuresCol=\"features\",labelCol=\"song_hotttnesss\")\n",
    "\n",
    "# Chain indexer and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, isoreg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform 4-fold cross validation:\n",
    "#paramGrid = ParamGridBuilder()\\\n",
    "#    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "#    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "#    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "#    .build()\n",
    "\n",
    "#crossval = CrossValidator(estimator=pipeline,\n",
    "#                          estimatorParamMaps=paramGrid,\n",
    "#                          evaluator=RegressionEvaluator(metricName ='rmse',labelCol=\"song_hotttnesss\"),\n",
    "#                          numFolds=4)\n",
    "\n",
    "# Train the model:\n",
    "model_isoreg = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test dataset:\n",
    "predictions_isoreg = model_isoreg.transform(test_df_model)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_isoreg.select(\"prediction\", \"song_hotttnesss\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator_isoreg = RegressionEvaluator(\n",
    "    labelCol=\"song_hotttnesss\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator_isoreg.evaluate(predictions_isoreg)\n",
    "\n",
    "# Print RMSE\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model_isoreg.stages[1].boundaries\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_isoreg.save(\"s3://whatever/models/isotonic/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PipelineModel.load(\"s3://whatever/models/isotonic/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print r2 value:\n",
    "print(f\" The r2 value is {model_isoreg.stages[1].summary.r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA snippet: to be included later....\n",
    "\n",
    "#pca = PCA(k=2, inputCol=\"features\",outputCol=\"features\")\n",
    "\n",
    "# Add the pca object to Pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
